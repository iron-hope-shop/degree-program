# What is a security vulnerability?
A security vulnerability is a finding within a system which could lead to unintended results.  This result could be on a physical system or an abstract one.  One example of a physical system is a locking mechanism, which could be picked if they were poorly constructed.  A physical system could also be hardware such as the USB port on a workstation.  In this case, the exploit could also relate to software as a hacker may use a BadUSB to effect changes on the workstation's operating system.  Vulnerabilities could be tangible or intangible but all could potentially lead to explotative use cases.

# What kinds of vulnerabilities would be identifiable in C++ code?
There are a range of vulnerabilities which would be identifiable in C++ code.  Some examples are mismanagement of variable such as unsigned integers being padded on systems which store it in 64 bits.  This type of vulnerability means values could potentially not be what the developer intended for them to be, resulting in unexpected behavior.  Although vulnerabilities like this are easily identified with simple unit tests, others-- like overflows and improper file handling-- can lead to data breaches.

# Why would you be looking for vulnerabilities during legacy to C++ conversion rather than during testing?
Someone may look for vulnerabilities during legacy to C++ conversion rather than during testing because there will always be gaps when converting the code.  I am not a master of software reverse engineering but I imagine there are a few times when interpretation can be skewed based on who is reverse engineering the product.  In some cases, a bad job may lead to huge vulnerabilties during the conversion so engineers should take the time to understand the code.

# How do you determine the appropriate fix to a security vulnerability?
I determine the appropriate fix to a vulnerability finding based on a few criteria.  First, it depends if the vulnerability was found in the application or in the container image layer.  Due to my current role these are the only layers which really apply to my projects.  If the vulnerability was found in the application, I may upgrade the offending package/library to a version where a fix is available.  If that is not possible, I have to change the package, the way I am implementing it, or apply a hardcoded fix to prevent exploitation of the vulnerability.  Sometimes the library is flagged but I am not using a class/method which is vulnerable.  In these cases it is important to outline to our internal teams that I am not proceeding with a known vulnerability.  On the other hand, if the vulnerability is in the container/docker image layer it is more of a pain (in my opinion).  Wrestling with Dockerfiles is something I do way too much.  I am not sure if it is pride but it is certainly my weakness.  In cases where it takes more than a day or a half day to fix the cascade of vulnerabilities found in some docker images, I try to use a template provided within our organization.  This way, the template image is maintained by another team.  In the event of another finding, THEY fix it and I reap the rewards!
