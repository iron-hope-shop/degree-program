<!--
    Template for Blackboard discussion board replies.
    Created/Maintained by: Bradley Jackson <me@brad-jackson.com>
-->

<head>
    <p style="text-align: left; font-weight: bold;">
        Izzy,
        <!-- UPDATE WITH OP'S NAME -->
        <span style="float: right">
            07/23/2023
        <!-- UPDATE -->
        </span>
    </p>
</head>

<body style="text-align: justify; padding: 8;">
    <br>
    <p style="line-height: 2; text-indent: 48px;">
        Your post brings up some really important points about the potential pitfalls of AI learning from biased or inappropriate data. The examples you provided, like Amazon's recruitment AI and the music creation AI, clearly illustrate how these systems can inadvertently perpetuate harmful biases if we're not careful.
        <!-- COPY/PASTA AS NEEDED FOR EACH SOURCE YOU HAVE! -->
    </p>
    <p style="line-height: 2; text-indent: 48px;">
        Your suggestion to remove gender from the equation in the recruitment AI is a good start, but as you pointed out, the AI might still develop biases based on other factors. One way to address this could be to ensure that the training data is representative of the diversity we see in the real world. This means not just removing potentially biasing information, but also actively seeking out and including diverse examples in the training data (Buolamwini & Gebru, 2018).
        <!-- COPY/PASTA AS NEEDED FOR EACH SOURCE YOU HAVE! -->
    </p>
    <p style="line-height: 2; text-indent: 48px;">
        For the music creation AI, you're right that simply adding more training data won't make it unlearn the offensive words it's already learned. One possible solution could be to implement a filtering system that prevents the AI from using certain offensive words or phrases. This could be combined with a retraining process using a more diverse and appropriate dataset (Hovy & Spruit, 2016).
        <!-- COPY/PASTA AS NEEDED FOR EACH SOURCE YOU HAVE! -->
    </p>
    <p style="line-height: 2; text-indent: 48px;">
        Another important aspect to consider is the role of ongoing monitoring and auditing. Even after an AI system has been deployed, it's crucial to regularly check its outputs and adjust the system as needed to prevent the perpetuation of harmful biases (Raji et al., 2020).
        <!-- COPY/PASTA AS NEEDED FOR EACH SOURCE YOU HAVE! -->
    </p>
    <br>
    <p style="text-align: left; font-weight: bold;">
        Regards,
        <!-- UPDATE -->
    </p>
    <p style="text-indent: 48px; font-weight: bold;">
        Brad
        <!-- UPDATE -->
    </p>
    <h4 style="text-align: center !important;">
        References
        <!-- UPDATE IF NEEDED -->
    </h4>
    <p style="padding-left:48px;text-indent:-48px;line-height:2">
        Buolamwini, J. & Gebru, T.. (2018). Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification. <i>Proceedings of Machine Learning Research, 81</i>, 77-91. <a href="https://proceedings.mlr.press/v81/buolamwini18a.html">https://proceedings.mlr.press/v81/buolamwini18a.html</a>
        <!-- 
            REMEBER TO UPDATE REFERENCES TO APA 6 FORMAT!!
            USING ITALICS, QUOTES, ETC!
            COPY/PASTA AS NEEDED FOR EACH SOURCE YOU HAVE!
        -->
    </p>
    <p style="padding-left:48px;text-indent:-48px;line-height:2">
        Hovy, D., & Spruit, S. L. (2016). The social impact of Natural Language Processing. <i>Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</i>. <a href="https://doi.org/10.18653/v1/p16-2096">https://doi.org/10.18653/v1/p16-2096</a>
        <!-- 
            REMEBER TO UPDATE REFERENCES TO APA 6 FORMAT!!
            USING ITALICS, QUOTES, ETC!
            COPY/PASTA AS NEEDED FOR EACH SOURCE YOU HAVE!
        -->
    </p>
    <p style="line-height: 2; padding-left: 48px; text-indent: -48px; line-height: 2;">
        Raji, I. D., Smart, A., White, R. N., Mitchell, M., Gebru, T., Hutchinson, B., Smith-Loud, J., Theron, D., & Barnes, P. (2020). Closing the AI accountability gap. <i>Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency</i>. <a href="https://doi.org/10.1145/3351095.3372873">https://doi.org/10.1145/3351095.3372873</a>
        <!-- 
            REMEBER TO UPDATE REFERENCES TO APA 6 FORMAT!!
            USING ITALICS, QUOTES, ETC!
            COPY/PASTA AS NEEDED FOR EACH SOURCE YOU HAVE!
        -->
    </p>
</body>