{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 1 of /Users/bradmin/apps/school/.conda/lib/python3.10/site-packages/distutils-precedence.pth:\n",
      "\n",
      "  Traceback (most recent call last):\n",
      "    File \"/Users/bradmin/apps/school/.conda/lib/python3.10/site.py\", line 186, in addpackage\n",
      "      exec(line)\n",
      "    File \"<string>\", line 1, in <module>\n",
      "  ModuleNotFoundError: No module named '_distutils_hack'\n",
      "\n",
      "Remainder of file ignored\n",
      "Requirement already satisfied: tensorflow in /Users/bradmin/apps/school/.conda/lib/python3.10/site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.13.0 in /Users/bradmin/apps/school/.conda/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-macos==2.13.0->tensorflow)\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-macos==2.13.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.1.21 (from tensorflow-macos==2.13.0->tensorflow)\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow-macos==2.13.0->tensorflow)\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/bradmin/apps/school/.conda/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/bradmin/apps/school/.conda/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.9.0)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-macos==2.13.0->tensorflow)\n",
      "  Downloading libclang-16.0.6-py2.py3-none-macosx_11_0_arm64.whl (20.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting numpy<=1.24.3,>=1.22 (from tensorflow-macos==2.13.0->tensorflow)\n",
      "  Using cached numpy-1.24.3-cp310-cp310-macosx_11_0_arm64.whl (13.9 MB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-macos==2.13.0->tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in /Users/bradmin/apps/school/.conda/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/bradmin/apps/school/.conda/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.23.4)\n",
      "Collecting setuptools (from tensorflow-macos==2.13.0->tensorflow)\n",
      "  Downloading setuptools-68.0.0-py3-none-any.whl (804 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m804.0/804.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /Users/bradmin/apps/school/.conda/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-macos==2.13.0->tensorflow)\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow-macos==2.13.0->tensorflow)\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-macos==2.13.0->tensorflow)\n",
      "  Using cached wrapt-1.15.0-cp310-cp310-macosx_11_0_arm64.whl (36 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/bradmin/apps/school/.conda/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.56.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/bradmin/apps/school/.conda/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow-macos==2.13.0->tensorflow)\n",
      "  Using cached tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow-macos==2.13.0->tensorflow)\n",
      "  Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/bradmin/apps/school/.conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0->tensorflow) (0.40.0)\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/Users/bradmin/apps/school/.conda/lib/python3.10/site-packages/google_pasta-0.2.0.dist-info/METADATA'\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0mError processing line 1 of /Users/bradmin/apps/school/.conda/lib/python3.10/site-packages/distutils-precedence.pth:\n",
      "\n",
      "  Traceback (most recent call last):\n",
      "    File \"/Users/bradmin/apps/school/.conda/lib/python3.10/site.py\", line 186, in addpackage\n",
      "      exec(line)\n",
      "    File \"<string>\", line 1, in <module>\n",
      "  ModuleNotFoundError: No module named '_distutils_hack'\n",
      "\n",
      "Remainder of file ignored\n",
      "Requirement already satisfied: numpy in /Users/bradmin/apps/school/.conda/lib/python3.10/site-packages (1.25.1)\n",
      "\u001b[33mWARNING: Error parsing requirements for google-pasta: [Errno 2] No such file or directory: '/Users/bradmin/apps/school/.conda/lib/python3.10/site-packages/google_pasta-0.2.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mError processing line 1 of /Users/bradmin/apps/school/.conda/lib/python3.10/site-packages/distutils-precedence.pth:\n",
      "\n",
      "  Traceback (most recent call last):\n",
      "    File \"/Users/bradmin/apps/school/.conda/lib/python3.10/site.py\", line 186, in addpackage\n",
      "      exec(line)\n",
      "    File \"<string>\", line 1, in <module>\n",
      "  ModuleNotFoundError: No module named '_distutils_hack'\n",
      "\n",
      "Remainder of file ignored\n",
      "Requirement already satisfied: keras in /Users/bradmin/apps/school/.conda/lib/python3.10/site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/bradmin/apps/school/.conda/lib/python3.10/site-packages (from keras) (1.25.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/bradmin/apps/school/.conda/lib/python3.10/site-packages (from keras) (1.11.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/bradmin/apps/school/.conda/lib/python3.10/site-packages (from keras) (1.16.0)\n",
      "Requirement already satisfied: pyyaml in /Users/bradmin/apps/school/.conda/lib/python3.10/site-packages (from keras) (6.0)\n",
      "Requirement already satisfied: h5py in /Users/bradmin/apps/school/.conda/lib/python3.10/site-packages (from keras) (3.9.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/bradmin/apps/school/.conda/lib/python3.10/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/bradmin/apps/school/.conda/lib/python3.10/site-packages (from keras) (1.1.2)\n",
      "\u001b[33mWARNING: Error parsing requirements for google-pasta: [Errno 2] No such file or directory: '/Users/bradmin/apps/school/.conda/lib/python3.10/site-packages/google_pasta-0.2.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install numpy\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'deserialize_keras_object' from 'keras.utils.generic_utils' (/Users/bradmin/apps/school/.conda/lib/python3.10/site-packages/keras/utils/generic_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Here is a sample Python script that uses the Keras library to create an OCR model based on the MNIST dataset:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Import necessary libraries\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Dense, Dropout, Flatten\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m \u001b[39mimport\u001b[39;00m Adam\n",
      "File \u001b[0;32m~/apps/school/.conda/lib/python3.10/site-packages/keras/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m absolute_import\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m applications\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n",
      "File \u001b[0;32m~/apps/school/.conda/lib/python3.10/site-packages/keras/activations.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m backend \u001b[39mas\u001b[39;00m K\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m deserialize_keras_object\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m Layer\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msoftmax\u001b[39m(x, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'deserialize_keras_object' from 'keras.utils.generic_utils' (/Users/bradmin/apps/school/.conda/lib/python3.10/site-packages/keras/utils/generic_utils.py)"
     ]
    }
   ],
   "source": [
    "# Here is a sample Python script that uses the Keras library to create an OCR model based on the MNIST dataset:\n",
    "# Import necessary libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import mnist\n",
    "from PIL import Image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess MNIST images (normalize pixel values to [0, 1])\n",
    "X_train = X_train.astype(\"float32\") / 255\n",
    "X_test = X_test.astype(\"float32\") / 255\n",
    "\n",
    "# Define OCR model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28 * 28, 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile OCR model with Adam optimizer and categorical cross-entropy loss function\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train OCR model on MNIST dataset\n",
    "model.fit(X_train, to_categorical(y_train), epochs=10, batch_size=128, validation_data=(X_test, to_categorical(y_test)))\n",
    "\n",
    "# # Use OCR model to recognize text in image files\n",
    "# # Load an image file\n",
    "# img = Image.open('image.png')\n",
    "\n",
    "# # Convert image to grayscale\n",
    "# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# # Resize image to 28x28 pixels\n",
    "# gray = cv2.resize(gray, (28, 28))\n",
    "\n",
    "# # Convert image to np.array and flatten\n",
    "# gray = np.array(gray).flatten()\n",
    "\n",
    "# # Use OCR model to recognize text in image\n",
    "# output = model.predict(gray)\n",
    "\n",
    "# # Print recognized text\n",
    "# print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
